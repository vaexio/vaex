{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T14:13:48.731159Z",
     "start_time": "2020-04-24T14:13:48.725142Z"
    }
   },
   "source": [
    "<style>\n",
    "pre {\n",
    " white-space: pre-wrap !important;\n",
    "}\n",
    ".table-striped > tbody > tr:nth-of-type(odd) {\n",
    "    background-color: #f9f9f9;\n",
    "}\n",
    ".table-striped > tbody > tr:nth-of-type(even) {\n",
    "    background-color: white;\n",
    "}\n",
    ".table-striped td, .table-striped th, .table-striped tr {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "    margin: 1em 2em;\n",
    "}\n",
    ".rendered_html td, .rendered_html th {\n",
    "    text-align: left;\n",
    "    vertical-align: middle;\n",
    "    padding: 4px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O Kung-Fu: get your data in and out of [Vaex](https://github.com/vaexio/vaex)\n",
    "\n",
    "## Data input\n",
    "\n",
    "Every project starts with reading in some data. Vaex supports several data sources:\n",
    "\n",
    "- Binary file formats:\n",
    " \n",
    "     - [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format#HDF5)\n",
    "     - [Apache Arrow](https://arrow.apache.org/)\n",
    "     - [Apache Parquet](https://parquet.apache.org/)\n",
    "     - [FITS](https://en.wikipedia.org/wiki/FITS)\n",
    "     \n",
    " - Text based file formats:\n",
    " \n",
    "     - [CSV](https://en.wikipedia.org/wiki/Comma-separated_values)\n",
    "     - [ASCII](https://en.wikipedia.org/wiki/Text_file)\n",
    "     - [JSON](https://www.json.org/json-en.html)\n",
    "     \n",
    " - In-memory data representations:\n",
    " \n",
    "     - [panads](https://pandas.pydata.org/) DataFrames and everything that pandas can read\n",
    "     - [Apache Arrow](https://arrow.apache.org/) Tables\n",
    "     - [numpy](https://numpy.org/) arrays\n",
    "     - Python dictionaries\n",
    "     - Single row DataFrames\n",
    "     \n",
    "The following examples show the best practices of getting your data in Vaex.\n",
    "\n",
    "### Binary file formats\n",
    "\n",
    "If your data is already in one of the supported binary file formats (HDF5, Apache Arrow, Apache Parquet, FITS), opening it with Vaex rather simple:\n",
    "\n",
    "```\n",
    "import vaex \n",
    "\n",
    "df_1 = vaex.open('./my_data/my_file_1.hdf5')\n",
    "df_2 = vaex.open('./my_data/my_file_1.arrow')\n",
    "df_3 = vaex.open('./my_data/my_file_1.parquet')\n",
    "df_4 = vaex.open('./my_data/my_file_1.fits')\n",
    "```\n",
    "\n",
    "Opening such data is instantenous regardless of the file size on disk: Vaex will just memory-map the data instead of reading it in memory. This is the optimal way of working with large datasets that are larger than available RAM.\n",
    "\n",
    "If your data is contained within multiple files, one can open them all simultaneously like this:\n",
    "\n",
    "```\n",
    "df = vaex.open('./my_data/my_file*.hdf5')\n",
    "# alternatively\n",
    "df = vaex.open_many(['./my_data/my_file_1.hdf5', './my_data/my_file_2.hdf5', './my_data/my_file_2.hdf5'])\n",
    "```\n",
    "The result will be a single DataFrame object containing all of the data coming from all files.\n",
    "\n",
    "The data does not necessarily have to be local. With Vaex you can open a HDF5 file straight from Amazon's S3:\n",
    "\n",
    "```\n",
    "df = vaex.open('s3://vaex/taxi/yellow_taxi_2009_2015_f32.hdf5?anon=true')\n",
    "```\n",
    "\n",
    "In this case the data will be lazily downloaded and cached to the local machine. \"Lazily downloaded\" means that Vaex will only download the portions of the data you really need. For example: imagine that we have a file hosted on S3 that has 100 columns and 1 billion rows. Getting a preview of the DataFrame via `print(df)` for instance will download only the first and last 5 rows. If we than proceed to make calculations or plots with only 5 columns, only the data from those columns will be downloaded and caches to the local machine. \n",
    "\n",
    "By default, data that is streamed from S3 is cached at ` $HOME/.vaex/file-cache/s3`, and thus successive access is as fast as native disk access. One can also use the `profile_name` argument to use a specific S3 profile, which will than be passed to `s3fs.core.S3FileSystem`.\n",
    "\n",
    "### Text based file formats\n",
    "\n",
    "Datasets are still commonly stored in text-based file formats such as CSV. Since text-based file formats are not memory-mappable, they have to be read in memory. If the contents of a CSV file fits into the available RAM, one can simply do:\n",
    "\n",
    "```\n",
    "df = vaex.from_csv('./my_data/my_file.csv')\n",
    "# or alternatively \n",
    "df = vaex.read_csv('./my_data/my_file.csv')  # `vaex.read_csv` is an alias to `vaex.from_csv`\n",
    "```\n",
    "\n",
    "Vaex is using pandas for reading CSV files in the background, so one can pass any arguments to the `vaex.from_csv` or `vaex.read_csv` as one would pass to `pandas.read_csv` and specify for example separators, column names and column types. In addition to this, if you specify the `convert=True` argument, the data will be automatically converted to an HDF5 file format behind the scenes, thus freeing RAM and allowing you to work with your data in a memory-efficient, out-of-core manner.\n",
    "\n",
    "If the CSV file is so large that it can not fit into RAM all at one time, one can convert the data to HDF5 simply by:\n",
    "\n",
    "```\n",
    "df = vaex.from_csv('./my_data/my_big_file.csv', convert=True, chunk_size=5_000_000)\n",
    "```\n",
    "\n",
    "When the above line is executed, Vaex will read the CSV in chunks, and convert each chunk to a temporary HDF5 file on disk. All temporary files are then concatenated into a single HDF5 file, and the temporary files deleted. The size of the individual chunks to be read can be specified via the `chunk_size` argument. Note that this automatic conversion requires free disk space of twice the final HDF5 file size.\n",
    "\n",
    "It is also common the data to be stored in JSON files. To read such data in Vaex one can do:\n",
    "\n",
    "```\n",
    "df = vaex.from_json('./my_data/my_file.json')\n",
    "```\n",
    "\n",
    "This is a convenience method which simply wraps `pandas.read_json`, so the same arguments and file reading strategy applies.\n",
    "\n",
    "### In-memory data representations\n",
    "\n",
    "One can construct a Vaex DataFrame from a variety of in-memory data representations. Such a common operation is converting a pandas into a Vaex DataFrame:\n",
    "\n",
    "```\n",
    "df = vaex.from_pandas(pandas_df, copy_index=True)\n",
    "```\n",
    "The `copy_index` argument specifies whether the index column of a pandas DataFrame should be imported into the Vaex DataFrame. Converting a pandas into a Vaex DataFrame is particularly useful since pandas can read data from a large variety of file formats. For instance, we can use pandas to read data from a database, and then pass it to Vaex like so:\n",
    "\n",
    "```\n",
    "import vaex\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "connection_string = 'postgresql://readonly:' + 'my_password' + '@my-server.my-company.com:1234/database_name'\n",
    "engine = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "pandas_df = pd.read_sql_query('SELECT * FROM MYTABLE', con=engine)\n",
    "df = vaex.from_pandas(pandas_df, copy_index=False)\n",
    "```\n",
    "\n",
    "Another example is using pandas to read in [SAS](https://www.sas.com/en_us/home.html) files:\n",
    "\n",
    "```\n",
    "import vaex\n",
    "import pandas as pd\n",
    "\n",
    "pandas_df = pd.read_sas('./my_data/my_file.xport')\n",
    "df = vaex.from_pandas(pandas_df)\n",
    "```\n",
    "\n",
    "One can read in an [arrow table](https://arrow.apache.org/docs/python/generated/pyarrow.Table.html) as a Vaex DataFrame in a similar manner:\n",
    "\n",
    "```\n",
    "df = vaex.from_arrow_table(pa_table)\n",
    "```\n",
    "\n",
    "Constructing a Vaex DataFrame from numpy arrays can is done like this:\n",
    "\n",
    "```\n",
    "import vaex\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array(['dog', 'cat', 'mouse'])\n",
    "\n",
    "df = vaex.from_arrays(x=x, y=y)\n",
    "```\n",
    "\n",
    "Constructing a DataFrame from a Python dict is also straight-forward:\n",
    "\n",
    "```\n",
    "d = {'a': [1, 2, 3], 'b': ['dog', 'cat', 'mouse']}\n",
    "df = vaex.from_dict(d)\n",
    "```\n",
    "\n",
    "At times, one may need to create a single row DataFrame. Vaex has a convenience method which takes individual elements (scalars) and creates the DataFrame:\n",
    "\n",
    "```\n",
    "df = vaex.from_scalars(x=5, y='horse')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data export\n",
    "\n",
    "One can export Vaex data to multiple file or in-memory data representations:\n",
    "\n",
    " - Binary file formats:\n",
    " \n",
    "     - [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format#HDF5)\n",
    "     - [Apache Arrow](https://arrow.apache.org/)\n",
    "     - [Apache Parquet](https://parquet.apache.org/)\n",
    "     - [FITS](https://en.wikipedia.org/wiki/FITS)\n",
    "     \n",
    " - Text based file formats:\n",
    " \n",
    "     - [CSV](https://en.wikipedia.org/wiki/Comma-separated_values)\n",
    "     - [ASCII](https://en.wikipedia.org/wiki/Text_file)\n",
    "     \n",
    " - In-memory data representations:\n",
    "\n",
    "    - DataFrames:\n",
    "    \n",
    "         - [panads](https://pandas.pydata.org/) DataFrame\n",
    "         - [Apache Arrow](https://arrow.apache.org/) Table\n",
    "         - [numpy](https://numpy.org/) arrays\n",
    "         - [Dask](https://dask.org/) arrays\n",
    "         - Python dictionaries\n",
    "         - Python items list ( a list of ('column_name', data) tuples)\n",
    "\n",
    "    - Expressions:\n",
    "    \n",
    "         - [panads](https://pandas.pydata.org/) Series\n",
    "         - [numpy](https://numpy.org/) array\n",
    "         - [Dask](https://dask.org/) array\n",
    "         - Python list\n",
    "\n",
    "### Binary file formats\n",
    "\n",
    "The most efficient way to store data on disk when you work with Vaex is to use binary file formats. Vaex can export a DataFrame to HDF5, Apache Arrow, Apache Parquet and FITS:\n",
    "\n",
    "```\n",
    "df.export_hdf5('./my_output_data/data.hdf5')\n",
    "df.export_arrow('./my_output_data/data.arrow')\n",
    "df.export_parquet('./my_output_data/data.parquet')\n",
    "df.export_fits('./my_output_data/data.fits')\n",
    "```\n",
    "\n",
    "Alternatively, one can simply use\n",
    "\n",
    "```\n",
    "df.export('./my_output_data/data.hdf5')\n",
    "df.export('./my_output_data/data.arrow')\n",
    "df.export('./my_output_data/data.parquet')\n",
    "df.export('./my_output_data/data.fits')\n",
    "```\n",
    "\n",
    "where Vaex will determine the file format of the based on the specified extension of the file name. If the extension is not recognized, an exception will be raised. \n",
    "\n",
    "If your data is large, i.e. larger than the available RAM, we recomment exporting to HDF5. \n",
    "\n",
    "### Text based file format\n",
    "\n",
    "At times, it may be useful to export the data to disk in a text based file format such as CSV. In that case one can simply do:\n",
    "\n",
    "```\n",
    "df.export_csv('./my_output_data/data.csv')  # `chunk_size` has a default value of 1_000_000\n",
    "```\n",
    "\n",
    "The `df.export_csv` method is using `pandas_df.to_csv` behind the scenes, and thus one can pass any argument to `df.export_csv` as would to `pandas_df.to_csv`. The data is exported in chunks and the size of those chunks can be specified by the `chunk_size` argument in `df.export_csv`. In this way, data that is too large to fit in RAM can be saved to disk.\n",
    "\n",
    "### In memory data representation\n",
    "\n",
    "Python has a rich ecosystem comprised of various libraries for data manipulation, that offer different functionality. Thus, it is often useful to be able to pass data from one library to another. Vaex is able to pass on its data to other libraries via a number of in-memory representations.\n",
    "\n",
    "#### DataFrame representations\n",
    "\n",
    "A vaex DataFrame can be converted to a pandas DataFrame like so:\n",
    "\n",
    "```\n",
    "pandas_df = df.to_pandas_df()\n",
    "```\n",
    "\n",
    "For DataFrames that are too large to fit in memory, one can specify the `chunk_size` argument, and the `df.to_pandas_df(chunk_size=100_000)` returns an generator yileding a pandas DataFrame with as many rows as indicated by the `chunk_size` argument.\n",
    "\n",
    "Converting a Vaex DataFrame into an arrow table is similar:\n",
    "\n",
    "```\n",
    "# Get a single arrow table\n",
    "table = df.to_arrow_table()\n",
    "\n",
    "# Create a generator, yielding an arrow table with the specified number of rows\n",
    "gen = df.to_arrow_table(chunk_size=1_000_000)\n",
    "```\n",
    "\n",
    "A Vaex DataFrame can be lazily exposed as a Dask array:\n",
    "\n",
    "```\n",
    "ddf = df.to_dask_array()\n",
    "```\n",
    "\n",
    "Keeping it close to pure Python, one can export a Vaex DataFrame as a dictionary:\n",
    "```\n",
    "# Get a single Python dict\n",
    "d_dict = df.to_dict()\n",
    "\n",
    "# Create a generator, yielding a Python dict with the specified number of rows\n",
    "gen = df.to_dict(chunk_size=1_000_000)\n",
    "```\n",
    "\n",
    "By specifying the `array_type` argument, one can choose whether the data will be represented by numpy arrays, xarrays, or Python lists.\n",
    "\n",
    "Alternatively, one can also convert a DataFrame to a list of tuples, were the first element of the tuple is the column name, while the second element is the array representation of the data.\n",
    "\n",
    "```\n",
    "# Get a single item list\n",
    "items = df.to_items()\n",
    "\n",
    "# Create a generator, yielding an item list with the specified number of rows\n",
    "gen = df.to_items(chunk_size=1_000_000)\n",
    "```\n",
    "\n",
    "One can also export a DataFrame as a list of arrays (numpy, xarrays, or Python lists):\n",
    "```\n",
    "# Get a single list of arrays\n",
    "arrays = df.to_arrays(array_type=None)   # by default, array_type=None returns numpy arrays\n",
    "\n",
    "# Create a generator, yielding an list of lists with the specified number of rows\n",
    "gen = df.to_items(chunk_size=1_000_000, array_type='list')  # \n",
    "```\n",
    "\n",
    "#### Expression representations\n",
    "\n",
    "A single vaex Expression can be also converted to a variety of in-memory representations:\n",
    "\n",
    "```\n",
    "# pandas Series\n",
    "x_series = df.x.to_pandas_series()\n",
    "\n",
    "# numpy array\n",
    "x_numpy = df.x.to_numpy()\n",
    "\n",
    "# Dask array\n",
    "x_dask_array = df.x.to_dask_array()\n",
    "\n",
    "# Python list\n",
    "x_list = df.x.tolist()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of in-memory input and output\n",
    "\n",
    "### DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:58.740551Z",
     "start_time": "2020-04-28T11:24:57.431779Z"
    }
   },
   "outputs": [],
   "source": [
    "import vaex\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us construct a DataFrame via a couple of in-memory data representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:58.756608Z",
     "start_time": "2020-04-28T11:24:58.742643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  x</th><th style=\"text-align: right;\">  y</th><th>z  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\"> 10</td><td>dog</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\"> 20</td><td>cat</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    x    y  z\n",
       "  0    0   10  dog\n",
       "  1    1   20  cat"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a DataFrame from Numpy arrays\n",
    "x = np.arange(2)\n",
    "y = np.array([10, 20])\n",
    "z = np.array(['dog', 'cat'])\n",
    "\n",
    "\n",
    "df_1 = vaex.from_arrays(x=x, y=y, z=z)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:58.770081Z",
     "start_time": "2020-04-28T11:24:58.759418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  x</th><th style=\"text-align: right;\">  y</th><th>z    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\"> 30</td><td>cow  </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\"> 40</td><td>horse</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    x    y  z\n",
       "  0    2   30  cow\n",
       "  1    3   40  horse"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a DataFrame from Python dictionary\n",
    "data_dict = dict(x=[2, 3], y=[30, 40], z=['cow', 'horse'])\n",
    "\n",
    "df_2 = vaex.from_dict(data_dict)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:58.789327Z",
     "start_time": "2020-04-28T11:24:58.772719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  x</th><th style=\"text-align: right;\">  y</th><th>z    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\"> 50</td><td>mouse</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    x    y  z\n",
       "  0    4   50  mouse"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a single row DataFrame\n",
    "df_3 = vaex.from_scalars(x=4, y=50, z='mouse')\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us concatenate all the DataFrames above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:58.841145Z",
     "start_time": "2020-04-28T11:24:58.791657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  x</th><th style=\"text-align: right;\">  y</th><th>z    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">  0</td><td style=\"text-align: right;\"> 10</td><td>dog  </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">  1</td><td style=\"text-align: right;\"> 20</td><td>cat  </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i></td><td style=\"text-align: right;\">  2</td><td style=\"text-align: right;\"> 30</td><td>cow  </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i></td><td style=\"text-align: right;\">  3</td><td style=\"text-align: right;\"> 40</td><td>horse</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i></td><td style=\"text-align: right;\">  4</td><td style=\"text-align: right;\"> 50</td><td>mouse</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    x    y  z\n",
       "  0    0   10  dog\n",
       "  1    1   20  cat\n",
       "  2    2   30  cow\n",
       "  3    3   40  horse\n",
       "  4    4   50  mouse"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = vaex.concat([df_1, df_2, df_3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data into a Vaex DataFrame, it is quite easy to pass it on to other common in-memory representations, either in full or in chunks, so that memory issues can be avoided for as long as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.118819Z",
     "start_time": "2020-04-28T11:24:58.843415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>cow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>mouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x   y      z\n",
       "0  0  10    dog\n",
       "1  1  20    cat\n",
       "2  2  30    cow\n",
       "3  3  40  horse\n",
       "4  4  50  mouse"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = df.to_pandas_df()\n",
    "pandas_df  # looks the same doesn't it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.168622Z",
     "start_time": "2020-04-28T11:24:59.120755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "x: int64\n",
       "y: int64\n",
       "z: string"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_table = df.to_arrow_table()\n",
    "arrow_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.182598Z",
     "start_time": "2020-04-28T11:24:59.172670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3, 4]),\n",
       " array([10, 20, 30, 40, 50]),\n",
       " array(['dog', 'cat', 'cow', 'horse', 'mouse'], dtype=object)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays = df.to_arrays()\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.206440Z",
     "start_time": "2020-04-28T11:24:59.185327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([0, 1, 2, 3, 4]),\n",
       " 'y': array([10, 20, 30, 40, 50]),\n",
       " 'z': array(['dog', 'cat', 'cow', 'horse', 'mouse'], dtype=object)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = df.to_dict()\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.222360Z",
     "start_time": "2020-04-28T11:24:59.208649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x', array([0, 1, 2, 3, 4])),\n",
       " ('y', array([10, 20, 30, 40, 50])),\n",
       " ('z', array(['dog', 'cat', 'cow', 'horse', 'mouse'], dtype=object))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = df.to_items()\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the above methods `.to_arrays`, `.to_dict` and `to.items` return the data as numpy arrays. By specifying the `array_type` keyword argument in each of these 3 methods, we can choose whether to output the data as an xarray object, a standard Python list, or explicitly choose the numpy representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.722247Z",
     "start_time": "2020-04-28T11:24:59.227956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<xarray.DataArray (dim_0: 5)>\n",
       " array([0, 1, 2, 3, 4])\n",
       " Dimensions without coordinates: dim_0, <xarray.DataArray (dim_0: 5)>\n",
       " array([10, 20, 30, 40, 50])\n",
       " Dimensions without coordinates: dim_0, <xarray.DataArray (dim_0: 5)>\n",
       " array(['dog', 'cat', 'cow', 'horse', 'mouse'], dtype=object)\n",
       " Dimensions without coordinates: dim_0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as xarray\n",
    "arrays = df.to_arrays(array_type='xarray')\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.732439Z",
     "start_time": "2020-04-28T11:24:59.724358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4],\n",
       " [10, 20, 30, 40, 50],\n",
       " ['dog', 'cat', 'cow', 'horse', 'mouse']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as a Python list\n",
    "arrays = df.to_arrays(array_type='list')\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.753443Z",
     "start_time": "2020-04-28T11:24:59.735184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3, 4]),\n",
       " array([10, 20, 30, 40, 50]),\n",
       " array(['dog', 'cat', 'cow', 'horse', 'mouse'], dtype=object)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explicity choose numpy (same as the default None)\n",
    "arrays = df.to_arrays(array_type='numpy')\n",
    "arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DataFrames that are too large to fit into the available RAM, the above methods all support the `chunk_size` keyword argument. When specified, the methods return a generator, which in turn yields a chunk of data, in the specified format. The generator also yields the row number of the first and the last element of that chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.809938Z",
     "start_time": "2020-04-28T11:24:59.756235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3    x   y    z\n",
      "0  0  10  dog\n",
      "1  1  20  cat\n",
      "2  2  30  cow\n",
      "\n",
      "3 5    x   y      z\n",
      "0  3  40  horse\n",
      "1  4  50  mouse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_pandas =  df.to_pandas_df(chunk_size=3)\n",
    "for i1, i2, chunk in gen_pandas:\n",
    "    print(i1, i2, chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.836016Z",
     "start_time": "2020-04-28T11:24:59.814916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 [array([0, 1, 2]), array([10, 20, 30]), array(['dog', 'cat', 'cow'], dtype=object)]\n",
      "\n",
      "3 5 [array([3, 4]), array([40, 50]), array(['horse', 'mouse'], dtype=object)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_array = df.to_arrays(chunk_size=3)\n",
    "for i1, i2, chunk in gen_array:\n",
    "    print(i1, i2, chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.856382Z",
     "start_time": "2020-04-28T11:24:59.837902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 {'x': [0, 1, 2], 'y': [10, 20, 30], 'z': ['dog', 'cat', 'cow']}\n",
      "\n",
      "3 5 {'x': [3, 4], 'y': [40, 50], 'z': ['horse', 'mouse']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_dict = df.to_dict(chunk_size=3, array_type='list')\n",
    "for i1, i2, chunk in gen_dict:\n",
    "    print(i1, i2, chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also lazily pass a vaex DataFrame to dask arrays, so in principle no extra memory should be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.864428Z",
     "start_time": "2020-04-28T11:24:59.858202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 80 B </td> <td> 80 B </td></tr>\n",
       "    <tr><th> Shape </th><td> (5, 2) </td> <td> (5, 2) </td></tr>\n",
       "    <tr><th> Count </th><td> 2 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"98\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"48\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"48\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 48.000000,0.000000 48.000000,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"24.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2</text>\n",
       "  <text x=\"68.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,68.000000,60.000000)\">5</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<vaex-df-e5732a06-8942-11ea-9871, shape=(5, 2), dtype=int64, chunksize=(5, 2), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_arrays = df[['x', 'y']].to_dask_array()   # String support coming soon\n",
    "dask_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easily get in-memory representations of Vaex Expressions as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.874929Z",
     "start_time": "2020-04-28T11:24:59.867358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas Series\n",
    "x_series = df.x.to_pandas_series()\n",
    "x_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.884829Z",
     "start_time": "2020-04-28T11:24:59.877845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array\n",
    "x_numpy = df.x.to_numpy()\n",
    "x_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.893504Z",
     "start_time": "2020-04-28T11:24:59.887009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python list\n",
    "x_list = df.x.tolist()\n",
    "x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T11:24:59.912489Z",
     "start_time": "2020-04-28T11:24:59.895620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 40 B </td> <td> 40 B </td></tr>\n",
       "    <tr><th> Shape </th><td> (5,) </td> <td> (5,) </td></tr>\n",
       "    <tr><th> Count </th><td> 2 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"92\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"42\" x2=\"120\" y2=\"42\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"42\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"42\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,42.009890 0.000000,42.009890\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"62.009890\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >5</text>\n",
       "  <text x=\"140.000000\" y=\"21.004945\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,21.004945)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<vaex-expression-e578e338-8942-11ea-9871, shape=(5,), dtype=int64, chunksize=(5,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dask array - Lazily passed\n",
    "x_dask_array = df.x.to_dask_array()\n",
    "x_dask_array\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
